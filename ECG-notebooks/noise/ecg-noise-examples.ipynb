{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 'ECGData.mat'\n",
    "data = loadmat('ECGData.mat')\n",
    "ecg_data = data['ECGData']\n",
    "ecg_data_item = ecg_data[0, 0]\n",
    "\n",
    "# Extract 'Data' and 'Labels'\n",
    "Signals = ecg_data_item['Data']\n",
    "Labels_array = ecg_data_item['Labels']\n",
    "\n",
    "Labels = [Labels_array[i,0][0] for i in range(Labels_array.shape[0])]\n",
    "\n",
    "# Map labels\n",
    "Labels_mapped = []\n",
    "for label in Labels:\n",
    "    if label == 'NSR':\n",
    "        Labels_mapped.append('N')\n",
    "    elif label in ['ARR', 'CHF']:\n",
    "        Labels_mapped.append('A')\n",
    "    else:\n",
    "        Labels_mapped.append('Other')\n",
    "\n",
    "Labels_mapped = np.array(Labels_mapped)\n",
    "\n",
    "# Normalize signals\n",
    "Signals_normalized = []\n",
    "for signal in Signals:\n",
    "    signal = signal.astype(np.float32) \n",
    "    signal = (signal - np.mean(signal)) / np.std(signal)\n",
    "    Signals_normalized.append(signal)\n",
    "Signals_normalized = np.array(Signals_normalized)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "segment_labels_encoded = le.fit_transform(Labels_mapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Without Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro2017/project research/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.5565 - loss: 0.6844 - val_accuracy: 0.5758 - val_loss: 0.6559\n",
      "Epoch 2/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.6810 - loss: 0.6481 - val_accuracy: 0.7879 - val_loss: 0.6201\n",
      "Epoch 3/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.6926 - loss: 0.6206 - val_accuracy: 0.7273 - val_loss: 0.5968\n",
      "Epoch 4/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.6808 - loss: 0.6093 - val_accuracy: 0.7879 - val_loss: 0.5403\n",
      "Epoch 5/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.7724 - loss: 0.5598 - val_accuracy: 0.7879 - val_loss: 0.5128\n",
      "Epoch 6/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.7899 - loss: 0.5316 - val_accuracy: 0.7879 - val_loss: 0.5053\n",
      "Epoch 7/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.7588 - loss: 0.5514 - val_accuracy: 0.7576 - val_loss: 0.5311\n",
      "Epoch 8/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.7588 - loss: 0.5554 - val_accuracy: 0.8182 - val_loss: 0.5229\n",
      "Epoch 9/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.7724 - loss: 0.5500 - val_accuracy: 0.8182 - val_loss: 0.5465\n",
      "Epoch 10/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.7665 - loss: 0.5674 - val_accuracy: 0.7879 - val_loss: 0.5531\n",
      "Epoch 11/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.7841 - loss: 0.5636 - val_accuracy: 0.7879 - val_loss: 0.5500\n",
      "Epoch 12/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.7899 - loss: 0.5567 - val_accuracy: 0.7576 - val_loss: 0.5477\n",
      "Epoch 13/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.7821 - loss: 0.5552 - val_accuracy: 0.7576 - val_loss: 0.5351\n",
      "Epoch 14/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.7821 - loss: 0.5475 - val_accuracy: 0.7576 - val_loss: 0.5180\n",
      "Epoch 15/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.7743 - loss: 0.5311 - val_accuracy: 0.7576 - val_loss: 0.5072\n",
      "Epoch 16/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.7841 - loss: 0.5316 - val_accuracy: 0.7576 - val_loss: 0.5086\n",
      "Epoch 17/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.7802 - loss: 0.5186 - val_accuracy: 0.7576 - val_loss: 0.5141\n",
      "Epoch 18/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.7743 - loss: 0.5144 - val_accuracy: 0.7576 - val_loss: 0.5169\n",
      "Epoch 19/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.7665 - loss: 0.5225 - val_accuracy: 0.7576 - val_loss: 0.5183\n",
      "Epoch 20/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.7841 - loss: 0.5106 - val_accuracy: 0.7576 - val_loss: 0.5149\n",
      "Epoch 21/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.7489 - loss: 0.5380 - val_accuracy: 0.7879 - val_loss: 0.5100\n",
      "Epoch 22/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.7685 - loss: 0.5156 - val_accuracy: 0.7879 - val_loss: 0.5071\n",
      "Epoch 23/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.7529 - loss: 0.5345 - val_accuracy: 0.7879 - val_loss: 0.5111\n",
      "Epoch 24/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.7704 - loss: 0.5074 - val_accuracy: 0.7576 - val_loss: 0.5218\n",
      "Epoch 25/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.7704 - loss: 0.5103 - val_accuracy: 0.7879 - val_loss: 0.5225\n",
      "Epoch 1/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 10s/step - accuracy: 0.5290 - loss: 0.6912 - val_accuracy: 0.7273 - val_loss: 0.6763\n",
      "Epoch 2/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 9s/step - accuracy: 0.6751 - loss: 0.6720 - val_accuracy: 0.6970 - val_loss: 0.6654\n",
      "Epoch 3/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9s/step - accuracy: 0.6303 - loss: 0.6617 - val_accuracy: 0.6364 - val_loss: 0.6573\n",
      "Epoch 4/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 9s/step - accuracy: 0.6323 - loss: 0.6487 - val_accuracy: 0.6364 - val_loss: 0.6467\n",
      "Epoch 5/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8s/step - accuracy: 0.6284 - loss: 0.6374 - val_accuracy: 0.6970 - val_loss: 0.6340\n",
      "Epoch 6/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 9s/step - accuracy: 0.6731 - loss: 0.6292 - val_accuracy: 0.7273 - val_loss: 0.6189\n",
      "Epoch 7/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 9s/step - accuracy: 0.6868 - loss: 0.6099 - val_accuracy: 0.7879 - val_loss: 0.6019\n",
      "Epoch 8/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 9s/step - accuracy: 0.7431 - loss: 0.6039 - val_accuracy: 0.7879 - val_loss: 0.5849\n",
      "Epoch 9/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 10s/step - accuracy: 0.7704 - loss: 0.5834 - val_accuracy: 0.7879 - val_loss: 0.5644\n",
      "Epoch 10/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 10s/step - accuracy: 0.7899 - loss: 0.5604 - val_accuracy: 0.7879 - val_loss: 0.5507\n",
      "Epoch 11/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 10s/step - accuracy: 0.7724 - loss: 0.5535 - val_accuracy: 0.7879 - val_loss: 0.5345\n",
      "Epoch 12/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 10s/step - accuracy: 0.7606 - loss: 0.5484 - val_accuracy: 0.7879 - val_loss: 0.5098\n",
      "Epoch 13/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 10s/step - accuracy: 0.7763 - loss: 0.5275 - val_accuracy: 0.7879 - val_loss: 0.5033\n",
      "Epoch 14/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 9s/step - accuracy: 0.7880 - loss: 0.5218 - val_accuracy: 0.7879 - val_loss: 0.4928\n",
      "Epoch 15/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 10s/step - accuracy: 0.7685 - loss: 0.5167 - val_accuracy: 0.7879 - val_loss: 0.4886\n",
      "Epoch 16/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 9s/step - accuracy: 0.7919 - loss: 0.4881 - val_accuracy: 0.7879 - val_loss: 0.4831\n",
      "Epoch 17/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 11s/step - accuracy: 0.7685 - loss: 0.5067 - val_accuracy: 0.7879 - val_loss: 0.4783\n",
      "Epoch 18/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 9s/step - accuracy: 0.7743 - loss: 0.5051 - val_accuracy: 0.7879 - val_loss: 0.4751\n",
      "Epoch 19/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 10s/step - accuracy: 0.7919 - loss: 0.4709 - val_accuracy: 0.7879 - val_loss: 0.4752\n",
      "Epoch 20/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 9s/step - accuracy: 0.7860 - loss: 0.4728 - val_accuracy: 0.7879 - val_loss: 0.4722\n",
      "Epoch 21/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 9s/step - accuracy: 0.7802 - loss: 0.4886 - val_accuracy: 0.7879 - val_loss: 0.4583\n",
      "Epoch 22/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 8s/step - accuracy: 0.7724 - loss: 0.4945 - val_accuracy: 0.7879 - val_loss: 0.4897\n",
      "Epoch 23/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 10s/step - accuracy: 0.7802 - loss: 0.4974 - val_accuracy: 0.7879 - val_loss: 0.4902\n",
      "Epoch 24/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 9s/step - accuracy: 0.7763 - loss: 0.4896 - val_accuracy: 0.7879 - val_loss: 0.4819\n",
      "Epoch 25/25\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 8s/step - accuracy: 0.7841 - loss: 0.4741 - val_accuracy: 0.7879 - val_loss: 0.4303\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step - accuracy: 0.7857 - loss: 0.5239\n",
      "RNN Test Accuracy without Noise: 0.7879\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 570ms/step - accuracy: 0.7857 - loss: 0.4311\n",
      "LSTM Test Accuracy without Noise: 0.7879\n"
     ]
    }
   ],
   "source": [
    "# For demonstration, let's proceed with normal noise. \n",
    "Signals_final = Signals_normalized  # Change to Signals_noisy_uniform or Signals_noisy_exponential to test others\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Signals_final, segment_labels_encoded, test_size=0.2, random_state=42, stratify=segment_labels_encoded)\n",
    "\n",
    "# Reshape for RNN/LSTM: [samples, timesteps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "### RNN Model ###\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(SimpleRNN(64, input_shape=(65536, 1), activation='tanh'))\n",
    "rnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "rnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "rnn_history = rnn_model.fit(X_train, y_train, epochs=25, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "### LSTM Model ###\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(64, input_shape=(65536, 1), activation='tanh'))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "lstm_history = lstm_model.fit(X_train, y_train, epochs=25, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate\n",
    "rnn_loss, rnn_accuracy = rnn_model.evaluate(X_test, y_test)\n",
    "print(f'RNN Test Accuracy without Noise: {rnn_accuracy:.4f}')\n",
    "\n",
    "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test, y_test)\n",
    "print(f'LSTM Test Accuracy without Noise: {lstm_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Functions Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_normal_noise(signals, noise_factor=0.1):\n",
    "    # noise_factor: fraction of the standard deviation of the signal\n",
    "    noisy_signals = []\n",
    "    for sig in signals:\n",
    "        sigma = np.std(sig)\n",
    "        noise = np.random.normal(0, sigma * noise_factor, sig.shape)\n",
    "        noisy_signals.append(sig + noise)\n",
    "    return np.array(noisy_signals)\n",
    "\n",
    "def add_uniform_noise(signals, noise_factor=0.1):\n",
    "    # noise_factor: fraction of the standard deviation of the signal\n",
    "    noisy_signals = []\n",
    "    for sig in signals:\n",
    "        sigma = np.std(sig)\n",
    "        # Range of uniform noise: [-sigma*noise_factor, sigma*noise_factor]\n",
    "        noise = np.random.uniform(-sigma * noise_factor, sigma * noise_factor, sig.shape)\n",
    "        noisy_signals.append(sig + noise)\n",
    "    return np.array(noisy_signals)\n",
    "\n",
    "def add_exponential_noise(signals, noise_factor=0.1):\n",
    "    # For exponential noise, we take an exponential distribution and adjust by noise_factor\n",
    "    noisy_signals = []\n",
    "    for sig in signals:\n",
    "        sigma = np.std(sig)\n",
    "        # scale for exponential distribution can be sigma * noise_factor\n",
    "        noise = np.random.exponential(sigma * noise_factor, sig.shape)\n",
    "        # Exponential is always positive; we can center it by subtracting its mean to make it more symmetric\n",
    "        noise = noise - np.mean(noise)\n",
    "        noisy_signals.append(sig + noise)\n",
    "    return np.array(noisy_signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro2017/project research/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.4961 - loss: 0.7019 - val_accuracy: 0.8182 - val_loss: 0.6246\n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.6965 - loss: 0.6499 - val_accuracy: 0.7879 - val_loss: 0.6039\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.6771 - loss: 0.6317 - val_accuracy: 0.7273 - val_loss: 0.5952\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.6498 - loss: 0.6264 - val_accuracy: 0.7879 - val_loss: 0.5541\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.7315 - loss: 0.5640 - val_accuracy: 0.8182 - val_loss: 0.5082\n",
      "Epoch 1/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 10s/step - accuracy: 0.5992 - loss: 0.6877 - val_accuracy: 0.6970 - val_loss: 0.6757\n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9s/step - accuracy: 0.6342 - loss: 0.6728 - val_accuracy: 0.6364 - val_loss: 0.6657\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 11s/step - accuracy: 0.6518 - loss: 0.6602 - val_accuracy: 0.6667 - val_loss: 0.6574\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 11s/step - accuracy: 0.6732 - loss: 0.6487 - val_accuracy: 0.6061 - val_loss: 0.6471\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 11s/step - accuracy: 0.6576 - loss: 0.6362 - val_accuracy: 0.6364 - val_loss: 0.6342\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - accuracy: 0.8163 - loss: 0.5087\n",
      "RNN Test Accuracy with Noise: 0.8182\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 544ms/step - accuracy: 0.6430 - loss: 0.6329\n",
      "LSTM Test Accuracy with Noise: 0.6364\n"
     ]
    }
   ],
   "source": [
    "Signals_noisy_normal = add_normal_noise(Signals_normalized, noise_factor=0.05)\n",
    "\n",
    "# For demonstration, let's proceed with normal noise. \n",
    "Signals_final = Signals_noisy_normal  # Change to Signals_noisy_uniform or Signals_noisy_exponential to test others\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Signals_final, segment_labels_encoded, test_size=0.2, random_state=42, stratify=segment_labels_encoded)\n",
    "\n",
    "# Reshape for RNN/LSTM: [samples, timesteps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "### RNN Model ###\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(SimpleRNN(64, input_shape=(65536, 1), activation='tanh'))\n",
    "rnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "rnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "rnn_history = rnn_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "### LSTM Model ###\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(64, input_shape=(65536, 1), activation='tanh'))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "lstm_history = lstm_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate\n",
    "rnn_loss, rnn_accuracy = rnn_model.evaluate(X_test, y_test)\n",
    "print(f'RNN Test Accuracy with Noise: {rnn_accuracy:.4f}')\n",
    "\n",
    "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test, y_test)\n",
    "print(f'LSTM Test Accuracy with Noise: {lstm_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro2017/project research/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.4630 - loss: 0.7021 - val_accuracy: 0.5455 - val_loss: 0.6756\n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.6109 - loss: 0.6701 - val_accuracy: 0.6061 - val_loss: 0.6639\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.6771 - loss: 0.6499 - val_accuracy: 0.6667 - val_loss: 0.6543\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.6615 - loss: 0.6324 - val_accuracy: 0.6970 - val_loss: 0.6257\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.7219 - loss: 0.5968 - val_accuracy: 0.7879 - val_loss: 0.5697\n",
      "Epoch 1/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 10s/step - accuracy: 0.4591 - loss: 0.6920 - val_accuracy: 0.7879 - val_loss: 0.6822\n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 12s/step - accuracy: 0.7763 - loss: 0.6773 - val_accuracy: 0.7879 - val_loss: 0.6706\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 11s/step - accuracy: 0.7802 - loss: 0.6634 - val_accuracy: 0.7879 - val_loss: 0.6576\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 11s/step - accuracy: 0.7802 - loss: 0.6492 - val_accuracy: 0.7879 - val_loss: 0.6421\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 11s/step - accuracy: 0.7802 - loss: 0.6317 - val_accuracy: 0.7879 - val_loss: 0.6206\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338ms/step - accuracy: 0.7857 - loss: 0.5700\n",
      "RNN Test Accuracy with Noise: 0.7879\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 544ms/step - accuracy: 0.7857 - loss: 0.6211\n",
      "LSTM Test Accuracy with Noise: 0.7879\n"
     ]
    }
   ],
   "source": [
    "Signals_noisy_uniform = add_uniform_noise(Signals_normalized, noise_factor=0.05)\n",
    "\n",
    "# For demonstration, let's proceed with normal noise. \n",
    "Signals_final = Signals_noisy_uniform  # Change to Signals_noisy_uniform or Signals_noisy_exponential to test others\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Signals_final, segment_labels_encoded, test_size=0.2, random_state=42, stratify=segment_labels_encoded)\n",
    "\n",
    "# Reshape for RNN/LSTM: [samples, timesteps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "### RNN Model ###\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(SimpleRNN(64, input_shape=(65536, 1), activation='tanh'))\n",
    "rnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "rnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "rnn_history = rnn_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "### LSTM Model ###\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(64, input_shape=(65536, 1), activation='tanh'))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "lstm_history = lstm_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate\n",
    "rnn_loss, rnn_accuracy = rnn_model.evaluate(X_test, y_test)\n",
    "print(f'RNN Test Accuracy with Noise: {rnn_accuracy:.4f}')\n",
    "\n",
    "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test, y_test)\n",
    "print(f'LSTM Test Accuracy with Noise: {lstm_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Signals_noisy_exponential = add_exponential_noise(Signals_normalized, noise_factor=0.05)\n",
    "\n",
    "# For demonstration, let's proceed with normal noise. \n",
    "Signals_final = Signals_noisy_exponential  # Change to Signals_noisy_uniform or Signals_noisy_exponential to test others\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Signals_final, segment_labels_encoded, test_size=0.2, random_state=42, stratify=segment_labels_encoded)\n",
    "\n",
    "# Reshape for RNN/LSTM: [samples, timesteps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "### RNN Model ###\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(SimpleRNN(64, input_shape=(65536, 1), activation='tanh'))\n",
    "rnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "rnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "rnn_history = rnn_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "### LSTM Model ###\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(64, input_shape=(65536, 1), activation='tanh'))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "lstm_history = lstm_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate\n",
    "rnn_loss, rnn_accuracy = rnn_model.evaluate(X_test, y_test)\n",
    "print(f'RNN Test Accuracy with Noise: {rnn_accuracy:.4f}')\n",
    "\n",
    "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test, y_test)\n",
    "print(f'LSTM Test Accuracy with Noise: {lstm_accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this study we perform a multiclass analysis combining both datasets - training2017 and ECGData.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 1 – Imports + global config\n",
    "# ==============================================================\n",
    "\n",
    "import os, math, random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import resample_poly\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Conv1D, BatchNormalization, ReLU,\n",
    "                                     GlobalAveragePooling1D, Dense, Dropout)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "# ---- unified sampling rate (both datasets already 300 Hz) ----\n",
    "FS_TARGET = 300        # Hz\n",
    "WIN_SEC   = 15         # length of each segment in seconds\n",
    "WIN_SAMPLES = WIN_SEC * FS_TARGET   # 4 500 samples\n",
    "STEP      = WIN_SAMPLES // 2        # 50 % overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 2 – Shared helpers\n",
    "# ==============================================================\n",
    "\n",
    "def zscore(x: np.ndarray) -> np.ndarray:\n",
    "    return (x - x.mean()) / (x.std() + 1e-7)\n",
    "\n",
    "def resample_to_target(x: np.ndarray, fs_src: int) -> np.ndarray:\n",
    "    if fs_src == FS_TARGET:\n",
    "        return x\n",
    "    gcd  = math.gcd(fs_src, FS_TARGET)\n",
    "    up   = FS_TARGET // gcd\n",
    "    down = fs_src   // gcd\n",
    "    return resample_poly(x, up, down)\n",
    "\n",
    "def segment_signal(x: np.ndarray,\n",
    "                   win: int = WIN_SAMPLES,\n",
    "                   step: int = STEP) -> List[np.ndarray]:\n",
    "    if len(x) < win:\n",
    "        x = np.pad(x, (0, win - len(x)))\n",
    "    return [x[s:s+win] for s in range(0, len(x)-win+1, step)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 3 – Load PhysioNet-2017 (4-class) → binary\n",
    "# ==============================================================\n",
    "\n",
    "def load_physionet2017_binary(root: str) -> Tuple[List[np.ndarray], List[int], List[str]]:\n",
    "    \"\"\"Return signals, labels (0=Normal,1=Arrhythmia), groups(rec-id).\"\"\"\n",
    "    ref = pd.read_csv(Path(root) / \"REFERENCE.csv\", header=None,\n",
    "                      names=[\"record\", \"label\"])\n",
    "    map4to2 = {\"N\": 0, \"A\": 1, \"O\": 1, \"~\": 1}\n",
    "    sigs, ys, gids = [], [], []\n",
    "    for rec, lbl4 in zip(ref.record, ref.label):\n",
    "        mat = loadmat(Path(root) / f\"{rec}.mat\")[\"val\"][0]\n",
    "        sig = zscore(mat.astype(np.float32))\n",
    "        sigs.append(resample_to_target(sig, fs_src=300))   # 2017 is 300 Hz\n",
    "        ys.append(map4to2[lbl4])\n",
    "        gids.append(rec)                                   # group by record\n",
    "    return sigs, ys, gids\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 3b – Load ECGData.mat subset → binary\n",
    "# ==============================================================\n",
    "\n",
    "def load_ecgdata_binary(mat_path: str) -> Tuple[List[np.ndarray], List[int], List[str]]:\n",
    "    \"\"\"Map: NSR→0, ARR/CHF→1, others dropped.\"\"\"\n",
    "    d      = loadmat(mat_path)[\"ECGData\"][0,0]\n",
    "    signals = d[\"Data\"]        # (162, 65536)\n",
    "    labels  = [lbl[0] for lbl in d[\"Labels\"][:,0]]  # to list of strings\n",
    "\n",
    "    keep_mask = [lbl in (\"NSR\",\"ARR\",\"CHF\") for lbl in labels]\n",
    "    signals = signals[keep_mask]\n",
    "    labels  = np.array(labels)[keep_mask]\n",
    "\n",
    "    sigs, ys, gids = [], [], []\n",
    "    for i, (sig_raw, lbl) in enumerate(zip(signals, labels)):\n",
    "        sig = zscore(sig_raw.astype(np.float32))\n",
    "        sigs.append(resample_to_target(sig, fs_src=300))   # file documented 300 Hz\n",
    "        ys.append(0 if lbl==\"NSR\" else 1)\n",
    "        gids.append(f\"ECGData_{i}\")\n",
    "    return sigs, ys, gids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 4 – Merge, segment, stack\n",
    "# ==============================================================\n",
    "\n",
    "def build_dataset() -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    # --- paths ---\n",
    "    phys_root = \"training2017\"\n",
    "    ecg_mat   = \"ECGData.mat\"\n",
    "\n",
    "    sig_a, y_a, gid_a = load_physionet2017_binary(phys_root)\n",
    "    sig_b, y_b, gid_b = load_ecgdata_binary(ecg_mat)\n",
    "\n",
    "    sigs   = sig_a + sig_b\n",
    "    labels = y_a   + y_b\n",
    "    gids   = gid_a + gid_b\n",
    "\n",
    "    segments, y_seg, g_seg = [], [], []\n",
    "    for sig, y, gid in zip(sigs, labels, gids):\n",
    "        for seg in segment_signal(sig):\n",
    "            segments.append(seg)\n",
    "            y_seg.append(y)\n",
    "            g_seg.append(gid)   # propagate record id\n",
    "\n",
    "    X = np.stack(segments, dtype=np.float32)      # (N, 4500)\n",
    "    y = np.array(y_seg, dtype=np.int32)           # (N,)\n",
    "    g = np.array(g_seg)\n",
    "    return X, y, g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 5 – Generator & tiny baseline CNN\n",
    "# ==============================================================\n",
    "\n",
    "class BatchGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, X, y, batch=64, shuffle=True):\n",
    "        self.X, self.y = X, y\n",
    "        self.batch = batch\n",
    "        self.idxs  = np.arange(len(X))\n",
    "        self.shuffle = shuffle\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.idxs)\n",
    "\n",
    "    def __len__(self): return math.ceil(len(self.X)/self.batch)\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.idxs[i*self.batch:(i+1)*self.batch]\n",
    "        x   = self.X[idx][...,None]     # add channel dim\n",
    "        y   = self.y[idx][:,None]       # shape (B,1)\n",
    "        return x, y\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle: np.random.shuffle(self.idxs)\n",
    "\n",
    "\n",
    "def build_tiny_cnn(input_len: int = WIN_SAMPLES) -> Model:\n",
    "    inp = Input(shape=(input_len,1))\n",
    "    x   = Conv1D(32, 15, strides=2, padding='same', activation='relu')(inp)\n",
    "    x   = BatchNormalization()(x)\n",
    "    x   = Conv1D(64,15,strides=2,padding='same',activation='relu')(x)\n",
    "    x   = BatchNormalization()(x)\n",
    "    x   = GlobalAveragePooling1D()(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    return Model(inp, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segments shape: (32455, 4500) | Positive ratio: 0.468\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4500\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2250\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2250\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1125\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m30,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1125\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,745</span> (124.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,745\u001b[0m (124.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,553</span> (123.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,553\u001b[0m (123.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro2017/project research/.venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 73ms/step - AUPRC: 0.5476 - accuracy: 0.6208 - loss: 0.6515 - val_AUPRC: 0.5785 - val_accuracy: 0.6243 - val_loss: 0.6588\n",
      "Epoch 2/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 84ms/step - AUPRC: 0.6256 - accuracy: 0.6605 - loss: 0.6268 - val_AUPRC: 0.6485 - val_accuracy: 0.6421 - val_loss: 0.6430\n",
      "Epoch 3/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 80ms/step - AUPRC: 0.6442 - accuracy: 0.6775 - loss: 0.6110 - val_AUPRC: 0.6608 - val_accuracy: 0.6090 - val_loss: 0.7234\n",
      "Epoch 4/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 84ms/step - AUPRC: 0.6565 - accuracy: 0.6824 - loss: 0.6040 - val_AUPRC: 0.6619 - val_accuracy: 0.6724 - val_loss: 0.6166\n",
      "Epoch 5/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 80ms/step - AUPRC: 0.6908 - accuracy: 0.6990 - loss: 0.5860 - val_AUPRC: 0.6830 - val_accuracy: 0.6859 - val_loss: 0.6074\n",
      "Epoch 6/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - AUPRC: 0.6879 - accuracy: 0.7004 - loss: 0.5820 - val_AUPRC: 0.6868 - val_accuracy: 0.6789 - val_loss: 0.6083\n",
      "Epoch 7/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - AUPRC: 0.7114 - accuracy: 0.7130 - loss: 0.5682 - val_AUPRC: 0.6845 - val_accuracy: 0.6888 - val_loss: 0.6078\n",
      "Epoch 8/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - AUPRC: 0.7076 - accuracy: 0.7160 - loss: 0.5695 - val_AUPRC: 0.6835 - val_accuracy: 0.6908 - val_loss: 0.5970\n",
      "Epoch 9/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - AUPRC: 0.7135 - accuracy: 0.7213 - loss: 0.5629 - val_AUPRC: 0.7091 - val_accuracy: 0.6987 - val_loss: 0.5899\n",
      "Epoch 10/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - AUPRC: 0.7305 - accuracy: 0.7287 - loss: 0.5504 - val_AUPRC: 0.7055 - val_accuracy: 0.6964 - val_loss: 0.5878\n",
      "Epoch 11/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 86ms/step - AUPRC: 0.7185 - accuracy: 0.7237 - loss: 0.5584 - val_AUPRC: 0.7193 - val_accuracy: 0.7030 - val_loss: 0.5786\n",
      "Epoch 12/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - AUPRC: 0.7303 - accuracy: 0.7290 - loss: 0.5514 - val_AUPRC: 0.7146 - val_accuracy: 0.7111 - val_loss: 0.5821\n",
      "Epoch 13/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 76ms/step - AUPRC: 0.7368 - accuracy: 0.7338 - loss: 0.5427 - val_AUPRC: 0.6877 - val_accuracy: 0.6921 - val_loss: 0.5949\n",
      "Epoch 14/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 79ms/step - AUPRC: 0.7400 - accuracy: 0.7400 - loss: 0.5425 - val_AUPRC: 0.7302 - val_accuracy: 0.7148 - val_loss: 0.5718\n",
      "Epoch 15/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 76ms/step - AUPRC: 0.7489 - accuracy: 0.7418 - loss: 0.5345 - val_AUPRC: 0.7107 - val_accuracy: 0.7010 - val_loss: 0.5898\n",
      "Epoch 16/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 77ms/step - AUPRC: 0.7573 - accuracy: 0.7408 - loss: 0.5313 - val_AUPRC: 0.7300 - val_accuracy: 0.7181 - val_loss: 0.5682\n",
      "Epoch 17/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 76ms/step - AUPRC: 0.7455 - accuracy: 0.7368 - loss: 0.5381 - val_AUPRC: 0.7230 - val_accuracy: 0.7082 - val_loss: 0.5826\n",
      "Epoch 18/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 83ms/step - AUPRC: 0.7518 - accuracy: 0.7414 - loss: 0.5332 - val_AUPRC: 0.7342 - val_accuracy: 0.7117 - val_loss: 0.5772\n",
      "Epoch 19/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - AUPRC: 0.7568 - accuracy: 0.7440 - loss: 0.5309 - val_AUPRC: 0.7299 - val_accuracy: 0.7140 - val_loss: 0.5782\n",
      "Epoch 20/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - AUPRC: 0.7585 - accuracy: 0.7533 - loss: 0.5201 - val_AUPRC: 0.7394 - val_accuracy: 0.7231 - val_loss: 0.5712\n",
      "Epoch 21/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 78ms/step - AUPRC: 0.7557 - accuracy: 0.7462 - loss: 0.5303 - val_AUPRC: 0.7352 - val_accuracy: 0.6772 - val_loss: 0.6153\n",
      "Epoch 22/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 76ms/step - AUPRC: 0.7678 - accuracy: 0.7511 - loss: 0.5220 - val_AUPRC: 0.7426 - val_accuracy: 0.7297 - val_loss: 0.5565\n",
      "Epoch 23/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - AUPRC: 0.7677 - accuracy: 0.7528 - loss: 0.5196 - val_AUPRC: 0.7500 - val_accuracy: 0.7202 - val_loss: 0.5659\n",
      "Epoch 24/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 81ms/step - AUPRC: 0.7638 - accuracy: 0.7506 - loss: 0.5240 - val_AUPRC: 0.7288 - val_accuracy: 0.6960 - val_loss: 0.6554\n",
      "Epoch 25/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 76ms/step - AUPRC: 0.7718 - accuracy: 0.7577 - loss: 0.5108 - val_AUPRC: 0.7484 - val_accuracy: 0.7183 - val_loss: 0.5618\n",
      "Epoch 26/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 77ms/step - AUPRC: 0.7659 - accuracy: 0.7534 - loss: 0.5201 - val_AUPRC: 0.7486 - val_accuracy: 0.7195 - val_loss: 0.5682\n",
      "Epoch 27/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 76ms/step - AUPRC: 0.7696 - accuracy: 0.7464 - loss: 0.5232 - val_AUPRC: 0.7530 - val_accuracy: 0.6906 - val_loss: 0.6025\n",
      "Epoch 28/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - AUPRC: 0.7843 - accuracy: 0.7600 - loss: 0.5095 - val_AUPRC: 0.7395 - val_accuracy: 0.7197 - val_loss: 0.5781\n",
      "Epoch 29/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - AUPRC: 0.7789 - accuracy: 0.7533 - loss: 0.5150 - val_AUPRC: 0.7459 - val_accuracy: 0.7243 - val_loss: 0.5592\n",
      "Epoch 30/30\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 75ms/step - AUPRC: 0.7838 - accuracy: 0.7573 - loss: 0.5061 - val_AUPRC: 0.7605 - val_accuracy: 0.7305 - val_loss: 0.5488\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 6 – Split, train, evaluate\n",
    "# ==============================================================\n",
    "\n",
    "X, y, groups = build_dataset()\n",
    "print(\"Segments shape:\", X.shape, \"| Positive ratio:\", y.mean().round(3))\n",
    "\n",
    "gss  = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=SEED)\n",
    "tr_i, te_i = next(gss.split(X, y, groups))\n",
    "gss2 = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=SEED)\n",
    "tr_i, va_i = next(gss2.split(X[tr_i], y[tr_i], groups[tr_i]))\n",
    "\n",
    "X_tr, y_tr = X[tr_i], y[tr_i]\n",
    "X_va, y_va = X[va_i], y[va_i]\n",
    "X_te, y_te = X[te_i], y[te_i]\n",
    "\n",
    "train_gen = BatchGen(X_tr, y_tr, batch=64, shuffle=True)\n",
    "val_gen   = BatchGen(X_va, y_va, batch=64, shuffle=False)\n",
    "\n",
    "model = build_tiny_cnn()\n",
    "model.compile(optimizer=Adam(1e-3),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy',\n",
    "                       tf.keras.metrics.AUC(curve='PR', name='AUPRC')])\n",
    "model.summary()\n",
    "\n",
    "cb_es = tf.keras.callbacks.EarlyStopping(patience=5,\n",
    "                                         restore_best_weights=True,\n",
    "                                         monitor='val_AUPRC',\n",
    "                                         mode='max')\n",
    "\n",
    "hist = model.fit(train_gen, epochs=30, validation_data=val_gen,\n",
    "                 callbacks=[cb_es], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "\n",
      "Confusion matrix:\n",
      "[[3030  525]\n",
      " [1167 1797]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7219    0.8523    0.7817      3555\n",
      "           1     0.7739    0.6063    0.6799      2964\n",
      "\n",
      "    accuracy                         0.7405      6519\n",
      "   macro avg     0.7479    0.7293    0.7308      6519\n",
      "weighted avg     0.7456    0.7405    0.7354      6519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 7 – Test metrics\n",
    "# ==============================================================\n",
    "\n",
    "y_pred_prob = model.predict(X_te[...,None], batch_size=128).ravel()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix(y_te, y_pred))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_te, y_pred, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
